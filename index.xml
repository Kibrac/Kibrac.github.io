<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Kibrac</title>
    <link>https://kibrac.github.io/</link>
    <description>Recent content in Home on Kibrac</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 09 Sep 2024 17:28:19 +0800</lastBuildDate>
    <atom:link href="https://kibrac.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Test</title>
      <link>https://kibrac.github.io/posts/test/</link>
      <pubDate>Mon, 09 Sep 2024 17:28:19 +0800</pubDate>
      <guid>https://kibrac.github.io/posts/test/</guid>
      <description>&lt;h2 id=&#34;11-深度学习介绍&#34;&gt;1.1 深度学习介绍&lt;/h2&gt;&#xA;&lt;h3 id=&#34;111-区别&#34;&gt;1.1.1 区别&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;深度学习和机器学习的区别&lt;/strong&gt;：深度学习并不需要过多的特征处理。&lt;/p&gt;&#xA;&lt;h4 id=&#34;1111-特征提取方面&#34;&gt;1.1.1.1 特征提取方面&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;机器学习的特征工程步骤是要靠手动完成的，而且需要大量领域专业知识&lt;/li&gt;&#xA;&lt;li&gt;深度学习通常由多个层构成，它们通常将更简单的模型组合在一起，通过将数据从一层传递到另一层来构建更复杂的模型。通过大量数据的训练自动得到模型，不需要人工设计特征提取环节。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;深度学习算法试图从数据中学习高级功能，这是深度学习的一个非常独特的功能。因此，减少了为了每个问题开发新特征提取器的任务。**适合用在难提取特征的图像、语音、自然语言领域。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;112-深度学习的应用场景&#34;&gt;1.1.2 深度学习的应用场景&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;图像识别&lt;/li&gt;&#xA;&lt;li&gt;自然语言处理&lt;/li&gt;&#xA;&lt;li&gt;语音技术&lt;/li&gt;&#xA;&lt;li&gt;机器学习效果不行的这些场景，特征需要复杂处理的地方&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;113-深度学习代表算法---神经网络&#34;&gt;1.1.3 深度学习代表算法 - 神经网络&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1131-神经网络&#34;&gt;1.1.3.1 神经网络&lt;/h4&gt;&#xA;&lt;p&gt;&lt;strong&gt;人工神经网络（Artificial Neural Network，简写为 ANN），也简称为神经网络（NN）&lt;/strong&gt;，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）结构和功能的&lt;strong&gt;计算模型&lt;/strong&gt;。经典的神经网络结构包含三个层次的神经网络，分别是&lt;strong&gt;输入层、隐藏层和输出层&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;图中每层的圆圈代表一个神经元，隐藏层和输出层的神经元有输入的数据计算后输出，输出层的神经元只是输入。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;神经网络的特点&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每个连接都有权值，同一层神经元之间没有连接&lt;/li&gt;&#xA;&lt;li&gt;神经元当中会包含有&lt;strong&gt;激活函数&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;最后的输出结果对应的层也称之为&lt;strong&gt;全连接层&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;114-为什么深度学习现在效果非常好&#34;&gt;1.1.4 为什么深度学习现在效果非常好&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据&lt;/li&gt;&#xA;&lt;li&gt;计算&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPU、TPU&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;算法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一些创新，如 [[ReLU 激活函数]]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;12-神经网络基础&#34;&gt;1.2 神经网络基础&lt;/h2&gt;&#xA;&lt;h3 id=&#34;121-logistic-回归&#34;&gt;1.2.1 Logistic 回归&lt;/h3&gt;&#xA;&lt;h4 id=&#34;1211-logistic-回归&#34;&gt;1.2.1.1 Logistic 回归&lt;/h4&gt;&#xA;&lt;p&gt;逻辑回归是一个主要用于二分分类的算法，那么逻辑回归是给定一个 $x$，输出一个该样本属于 $1$ 对应类别的预测概率 $\hat{y}=P(y=1|x)$。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
